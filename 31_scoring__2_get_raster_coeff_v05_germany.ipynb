{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48215353-8db0-471a-99fd-24c0eeb14008",
   "metadata": {},
   "source": [
    "# üìù Notebook-Dokumentation\n",
    "\n",
    "**Notebook:** `31_scoring__2_get_raster_coeff_v05_germany.ipynb`  \n",
    "**Beschreibung:**  \n",
    "Berechnet Zug√§nglichkeits-Scores f√ºr verschiedene Verkehrsmodi (`bike`, `my_bike_cycleways`, `cargo_bike`) auf 100‚ÄØm-Rasterebene, basierend auf gestanzten Isochronen (Isodonuts) und POI-Attributen.  \n",
    "Die Methode kombiniert Zeitgewichtung, r√§umliche Zuordnung und kategorienbasierte Limitierung der POIs zu einem intuitiven, vergleichbaren Scoring-Output.\n",
    "\n",
    "---\n",
    "\n",
    "### üì• Input\n",
    "\n",
    "- **Isodonut-Daten pro PLZ und Modus**  \n",
    "  z.‚ÄØB. `{input_folder_isodon}/53925_*_isoDonuts_6x5min__bike_simp0002.parquet`\n",
    "- **POI-Daten** (als `attr_all` von `data/attractions/attr_germany_all_shapes_25-05-12.parquet`) mit:\n",
    "  - Geometrie\n",
    "  - Score\n",
    "  - Kategorie (`cat`)\n",
    "  - POI-Typ (`poi_type`)\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Verarbeitungsschritte\n",
    "\n",
    "1. **Pro PLZ und Modus:**\n",
    "   - Laden der zugeh√∂rigen Isodonut-Datei\n",
    "   - Durchf√ºhrung eines r√§umlichen Joins zwischen Isodonut-Zonen und POIs\n",
    "   - Berechnung eines gewichteten Scores (`coeff`) pro POI unter Ber√ºcksichtigung des `time_bucket` (z.‚ÄØB. 5‚ÄØmin ‚Üí 1.0, 10‚ÄØmin ‚Üí 0.8, ...)\n",
    "\n",
    "2. **Kategoriebasierte Begrenzung:**\n",
    "   - Maximalanzahl an POIs je Kategorie/Typ pro Rasterzelle √ºber `set_category_limits()` (z.‚ÄØB. max. 3 Schulen)\n",
    "   - Selektion der relevantesten POIs basierend auf `coeff`\n",
    "\n",
    "3. **Aggregation:**\n",
    "   - Summierung der gewichteten Scores (`coeff`) pro Rasterzelle (`id`) und Modus\n",
    "\n",
    "4. **Export:**\n",
    "   - Speichern der aggregierten Scores pro Rasterzelle als CSV (`acc2raster_`)\n",
    "   - Optional: Speichern aller bewerteten POI-Zuordnungen als `.parquet` zur Nachvollziehbarkeit (`pois_w_score_all`) (nur f√ºr die interaktive Visualisierung ist das relevant)\n",
    "\n",
    "---\n",
    "\n",
    "### üì§ Output\n",
    "\n",
    "- `{output_folder_csv}/{plz}_acc2raster_.csv`  \n",
    "  ‚Üí Scoring-Resultate pro Rasterzelle und Modus\n",
    "- `{output_folder_csv}/{plz}_pois_w_score_all.parquet`  \n",
    "  ‚Üí POIs mit vollst√§ndigem Scoring je PLZ und Modus\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12310e74-e5ee-45c0-b2e9-0a462413c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01914332-41d9-4dc2-a1dd-4fecee81a727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi_index</th>\n",
       "      <th>name</th>\n",
       "      <th>cat</th>\n",
       "      <th>attr</th>\n",
       "      <th>score</th>\n",
       "      <th>geometry</th>\n",
       "      <th>osm_category</th>\n",
       "      <th>poi_type</th>\n",
       "      <th>stops_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Papa-Pizza</td>\n",
       "      <td>Freizeit und Kultur</td>\n",
       "      <td>attr_pois</td>\n",
       "      <td>0.5</td>\n",
       "      <td>POINT (6.94125 50.91559)</td>\n",
       "      <td>amenity</td>\n",
       "      <td>fast_food</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hartis Cafe</td>\n",
       "      <td>Freizeit und Kultur</td>\n",
       "      <td>attr_pois</td>\n",
       "      <td>0.5</td>\n",
       "      <td>POINT (6.96393 50.9052)</td>\n",
       "      <td>amenity</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Grundm√ºhle</td>\n",
       "      <td>Freizeit und Kultur</td>\n",
       "      <td>attr_pois</td>\n",
       "      <td>0.5</td>\n",
       "      <td>POINT (13.65719 51.11308)</td>\n",
       "      <td>amenity</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Shell</td>\n",
       "      <td>Versorgung (Lebensmittel)</td>\n",
       "      <td>attr_pois</td>\n",
       "      <td>2.5</td>\n",
       "      <td>POINT (13.64555 51.01484)</td>\n",
       "      <td>amenity</td>\n",
       "      <td>fuel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aral</td>\n",
       "      <td>Versorgung (Lebensmittel)</td>\n",
       "      <td>attr_pois</td>\n",
       "      <td>2.5</td>\n",
       "      <td>POINT (8.3896 48.99517)</td>\n",
       "      <td>amenity</td>\n",
       "      <td>fuel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919701</th>\n",
       "      <td>4919701</td>\n",
       "      <td>Klieken, Schule</td>\n",
       "      <td>OePNV Haltepunkt</td>\n",
       "      <td>pt_stops</td>\n",
       "      <td>1.5</td>\n",
       "      <td>POINT (12.3765 51.89085)</td>\n",
       "      <td>None</td>\n",
       "      <td>pt_stop</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919702</th>\n",
       "      <td>4919702</td>\n",
       "      <td>Coswig(Anh)</td>\n",
       "      <td>OePNV Haltepunkt</td>\n",
       "      <td>pt_stops</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POINT (12.45762 51.888)</td>\n",
       "      <td>None</td>\n",
       "      <td>pt_stop</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919703</th>\n",
       "      <td>4919703</td>\n",
       "      <td>Griebo</td>\n",
       "      <td>OePNV Haltepunkt</td>\n",
       "      <td>pt_stops</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POINT (12.52298 51.88058)</td>\n",
       "      <td>None</td>\n",
       "      <td>pt_stop</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919704</th>\n",
       "      <td>4919704</td>\n",
       "      <td>Klieken</td>\n",
       "      <td>OePNV Haltepunkt</td>\n",
       "      <td>pt_stops</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POINT (12.37178 51.89453)</td>\n",
       "      <td>None</td>\n",
       "      <td>pt_stop</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919705</th>\n",
       "      <td>4919705</td>\n",
       "      <td>Lutherstadt Wittenberg-Piesteritz</td>\n",
       "      <td>OePNV Haltepunkt</td>\n",
       "      <td>pt_stops</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POINT (12.59678 51.87186)</td>\n",
       "      <td>None</td>\n",
       "      <td>pt_stop</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4919706 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         poi_index                               name  \\\n",
       "0                0                         Papa-Pizza   \n",
       "1                1                        Hartis Cafe   \n",
       "2                2                         Grundm√ºhle   \n",
       "3                3                              Shell   \n",
       "4                4                               Aral   \n",
       "...            ...                                ...   \n",
       "4919701    4919701                    Klieken, Schule   \n",
       "4919702    4919702                        Coswig(Anh)   \n",
       "4919703    4919703                             Griebo   \n",
       "4919704    4919704                            Klieken   \n",
       "4919705    4919705  Lutherstadt Wittenberg-Piesteritz   \n",
       "\n",
       "                               cat       attr  score  \\\n",
       "0              Freizeit und Kultur  attr_pois    0.5   \n",
       "1              Freizeit und Kultur  attr_pois    0.5   \n",
       "2              Freizeit und Kultur  attr_pois    0.5   \n",
       "3        Versorgung (Lebensmittel)  attr_pois    2.5   \n",
       "4        Versorgung (Lebensmittel)  attr_pois    2.5   \n",
       "...                            ...        ...    ...   \n",
       "4919701           OePNV Haltepunkt   pt_stops    1.5   \n",
       "4919702           OePNV Haltepunkt   pt_stops    2.0   \n",
       "4919703           OePNV Haltepunkt   pt_stops    2.0   \n",
       "4919704           OePNV Haltepunkt   pt_stops    2.0   \n",
       "4919705           OePNV Haltepunkt   pt_stops    2.0   \n",
       "\n",
       "                          geometry osm_category    poi_type  stops_count  \n",
       "0         POINT (6.94125 50.91559)      amenity   fast_food          NaN  \n",
       "1          POINT (6.96393 50.9052)      amenity  restaurant          NaN  \n",
       "2        POINT (13.65719 51.11308)      amenity  restaurant          NaN  \n",
       "3        POINT (13.64555 51.01484)      amenity        fuel          NaN  \n",
       "4          POINT (8.3896 48.99517)      amenity        fuel          NaN  \n",
       "...                            ...          ...         ...          ...  \n",
       "4919701   POINT (12.3765 51.89085)         None     pt_stop         14.0  \n",
       "4919702    POINT (12.45762 51.888)         None     pt_stop         46.0  \n",
       "4919703  POINT (12.52298 51.88058)         None     pt_stop         39.0  \n",
       "4919704  POINT (12.37178 51.89453)         None     pt_stop         39.0  \n",
       "4919705  POINT (12.59678 51.87186)         None     pt_stop         46.0  \n",
       "\n",
       "[4919706 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all pois, calc scoring per raster and ...\n",
    "attr_all= gpd.read_parquet(\"data/attractions/attr_germany_all_shapes_25-05-12.parquet\")\n",
    "attr_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a9bdc-d034-4f31-bcbf-11e6d01741fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea83fdd-a875-4103-a3fc-a72a3500f675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2764ead-a9de-45df-874f-e4c5effc375e",
   "metadata": {},
   "source": [
    "### PRODUCTION functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "261ae679-03e7-44eb-a887-53ea953634e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scroing for each mode, setting cat_limits\n",
    "\n",
    "\n",
    "def set_category_limits(df):\n",
    "    # Define how many rows to keep for each category\n",
    "    category_row_limit = {\n",
    "        \"Bildung (Basis)\": 3,\n",
    "        \"Freizeit und Kultur\": 1,\n",
    "        \"Freizeit/Erholung Freiraum\": 1,\n",
    "        \"OePNV Haltepunkt\": 5, \n",
    "        \"Versorgung (Einzelhandel und Dienstleistungen)\": 1,\n",
    "        \"Versorgung (Lebensmittel)\": 3,\n",
    "        \"Verwaltung/Behoerden\": 1,\n",
    "        \"Gesundheit\": 3,\n",
    "        \"Weiterfuehrende/offene Bildung\": 2\n",
    "    }\n",
    "\n",
    "    # Get the total number of groups for tqdm progress bar\n",
    "    num_groups = df.groupby([\"id\", \"cat\", \"poi_type\"]).ngroups\n",
    "    # Initialize an empty list to collect filtered rows\n",
    "    filtered_rows = []\n",
    "   \n",
    "    \n",
    "    # Iterate over unique combinations of `Gitter_ID_100m`, `cat`, and `poi_type`\n",
    "    for (gid, cat, poi_type), group in tqdm(df.groupby([\"id\", \"cat\", \"poi_type\"]), \n",
    "                                        total=num_groups, \n",
    "                                        desc=\"Processing groups\"):\n",
    "        # Get the limit for this category\n",
    "        row_limit = category_row_limit.get(cat, 0)  # Default to 0 if category is not listed\n",
    "        # row_limit = 99 for testing\n",
    "        \n",
    "        # Sort the group by `coeff` in descending order\n",
    "        group_sorted = group.sort_values(\"coeff\", ascending=False)\n",
    "\n",
    "        # Select the top `row_limit` rows\n",
    "        filtered_group = group_sorted.head(row_limit)\n",
    "\n",
    "        # Store only row values instead of DataFrames\n",
    "        filtered_rows.extend(filtered_group.values.tolist())\n",
    "    \n",
    "    # Convert raw list of rows to a DataFrame **only once** at the end\n",
    "    #print(\"Concatenating filtered rows into final DataFrame...\")\n",
    "    dfsjoin_topN = pd.DataFrame(filtered_rows, columns=df.columns)\n",
    "    \n",
    "    return dfsjoin_topN\n",
    "\n",
    "    \n",
    "def spatial_join(gdf_iso, attr_all):\n",
    "    \"\"\"\n",
    "    Perform spatial join on `gdf_iso` without chunking.\n",
    "    \n",
    "    Parameters:\n",
    "    - gdf_iso (GeoDataFrame): Input GeoDataFrame to be joined.\n",
    "    - attr_all (GeoDataFrame): Attribute GeoDataFrame for spatial join.\n",
    "    \n",
    "    Returns:\n",
    "    - GeoDataFrame: Result of spatial join.\n",
    "    \"\"\"\n",
    "    #print(\"___________\")\n",
    "    #print(\"Performing spatial join...\")\n",
    "    \n",
    "    dfsjoin = gpd.sjoin(\n",
    "        gdf_iso, \n",
    "        attr_all[['geometry', 'score', 'attr', 'cat', 'name', 'poi_index', 'poi_type']], \n",
    "        how=\"inner\", \n",
    "        predicate=\"intersects\"\n",
    "    )\n",
    "    \n",
    "    #print(\"___________\") \n",
    "    #print(\"Spatial join completed.\")\n",
    "    \n",
    "    return dfsjoin\n",
    "\n",
    "\n",
    "def add_access_score(gdf_iso, mode):\n",
    "    #print (\"___________\") \n",
    "    #print(\"Start processing with spatial join...\")\n",
    "    # Perform chunked spatial join\n",
    "    dfsjoin = spatial_join(gdf_iso, attr_all)\n",
    "\n",
    "    #print (\"___________\") \n",
    "    #print (\"Adding coeff based on Score and time factors...\") \n",
    "    conditions = [\n",
    "        dfsjoin[\"time_bucket\"] == 5,\n",
    "        dfsjoin[\"time_bucket\"] == 10,\n",
    "        dfsjoin[\"time_bucket\"] == 15,\n",
    "        dfsjoin[\"time_bucket\"] == 20,\n",
    "        dfsjoin[\"time_bucket\"] == 25,\n",
    "        dfsjoin[\"time_bucket\"] == 30\n",
    "    ]\n",
    "    time_factors = [1, 0.8, 0.6, 0.4, 0.2, 0.1]\n",
    "    dfsjoin[\"coeff\"] = np.select(conditions, time_factors, default=0) * dfsjoin[\"score\"]\n",
    "\n",
    "    #print (\"___________\") \n",
    "    #print (\"Start with category_limits...\")\n",
    "    dfsjoin_cat_limit=set_category_limits(dfsjoin)\n",
    "\n",
    "    #print (\"___________\") \n",
    "    #print (\"Start grouping by IDs...\")\n",
    "    # future: dont need attr anymore as pt and rest will get the same\n",
    "    df_grouped_ID=dfsjoin_cat_limit.groupby(['id','attr'])['coeff'].sum().reset_index()\n",
    "    \n",
    "    df_grouped_ID['mode']=mode\n",
    "    #df_grouped_ID['attr']=attr\n",
    "\n",
    "    return df_grouped_ID, dfsjoin_cat_limit #for viz table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef4226-66a7-42d6-aa53-b08f1d19b6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b36be-38b0-41aa-acb5-ca691b8fd210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7312c03c-4728-44ba-980d-38021fcfe001",
   "metadata": {},
   "source": [
    "## generate acc2raster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da143b0-3039-487a-aedd-b0572fb85f9e",
   "metadata": {},
   "source": [
    "### what is been done here?\n",
    "#### input:\n",
    "* all attraction (osm pois and pt stops)\n",
    "* plz areas where isodons area fully available\n",
    "\n",
    "#### output:\n",
    "* csv where for each pofile and raster the coeff is stored\n",
    "* (parquet \"pois_w_score_all\", for visualisition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b879428-8a19-4591-a1d2-24efc9ff1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### set input and output folder\n",
    "\n",
    "scenario_name=\"test_plz_88636\"\n",
    "\n",
    "\n",
    "#input_folder_isodon = \"../../storage/isos_ger/isodon/\"\n",
    "input_folder_isodon  = f\"isochronen/{scenario_name}/isodon/\"\n",
    "\n",
    "output_folder_csv = f\"output/{scenario_name}/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7546a-2c3a-49d3-bcb1-31d343c8f99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d06ac88-89e5-4204-a3d7-e1fad281f869",
   "metadata": {},
   "source": [
    "### get the plz that need to be done (isodon done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8263c0c3-e9c9-4e32-b737-298f41cba2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLZs that appeared at least 3 times: (show only the first 100) ['88636']\n",
      "PLZs that appeared at least 3 times, number: 1\n",
      "PLZs that did NOT appear 3 times: []\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Get all files in the \"data/isos\" folder\n",
    "#files = glob.glob(\"data/isos/isodon/*\")\n",
    "#files = glob.glob(\"../../storage/isos_ger/isodon/*\")\n",
    "files = glob.glob(input_folder_isodon+\"*\")\n",
    "\n",
    "# Extract PLZ (assuming it's the first numeric part of the filename)\n",
    "plz_list = []\n",
    "for file in files:\n",
    "    match = re.search(r\"(\\d{5})\", file)  # Looks for a 5-digit number\n",
    "    if match:\n",
    "        plz_list.append(match.group(1))\n",
    "\n",
    "# Count occurrences of each PLZ\n",
    "plz_counts = Counter(plz_list)\n",
    "\n",
    "# Filter PLZs that appear at least 3 times\n",
    "valid_plz_isodon = [plz for plz, count in plz_counts.items() if count >= 3]\n",
    "\n",
    "# Find PLZs that did not appear at least 3 times\n",
    "invalid_plz = [plz for plz, count in plz_counts.items() if count < 3]\n",
    "\n",
    "# Print results\n",
    "print(\"PLZs that appeared at least 3 times: (show only the first 100)\", valid_plz_isodon[:100])\n",
    "print(\"PLZs that appeared at least 3 times, number:\", len(valid_plz_isodon))\n",
    "print(\"PLZs that did NOT appear 3 times:\", invalid_plz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f69f93-f897-4b91-90cb-33a66465a93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a1c870f-709f-49b7-8f7a-7d4898dc4e96",
   "metadata": {},
   "source": [
    "### check which plz have already been calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccc961f4-94b6-458b-9abe-ba0a04a8d9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLZs that are ready produeced scoring raster: []\n",
      "PLZs that are ready produeced scoring raster, number: 0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Get all files in the \"data/isos\" folder\n",
    "#files = glob.glob(\"data/germany/*\")\n",
    "files = glob.glob(output_folder_csv + \"*.csv\")\n",
    "\n",
    "# Extract PLZ (assuming it's the first numeric part of the filename)\n",
    "plz_list = []\n",
    "for file in files:\n",
    "    match = re.search(r\"(\\d{5})\", file)  # Looks for a 5-digit number\n",
    "    if match:\n",
    "        plz_list.append(match.group(1))\n",
    "\n",
    "# Count occurrences of each PLZ\n",
    "plz_counts = Counter(plz_list)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"PLZs that are ready produeced scoring raster:\", plz_list)\n",
    "print(\"PLZs that are ready produeced scoring raster, number:\", len(plz_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bda9d43-3e67-453d-b996-e24c81d7f991",
   "metadata": {},
   "source": [
    "### get which plz have to be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba91a5e-dfab-49fc-925e-3291b6eddf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find elements in B but not in A\n",
    "plz_difference_to_calc = list(set(valid_plz_isodon) - set(plz_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60134fab-6d5f-49ca-b437-edaea1600e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plz_difference_to_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a7542-8f2c-4a33-b2e0-7fda78bf9e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997e50cf-d8b2-4bf4-939d-03114b97e329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb2fea-9791-4fa9-bb62-f123a16e05bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b97bbc2a-7536-4f13-a5e4-8f67adae1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_isodon_file(input_folder, plz, m):\n",
    "    \"\"\"\n",
    "    Finds and reads a .parquet file for the given PLZ and m, ignoring the date in the filename.\n",
    "\n",
    "    Parameters:\n",
    "        input_folder (str): Path to the folder containing the files.\n",
    "        plz (str): Postal code or identifier in the filename.\n",
    "        m (str): Suffix used in the filename (e.g., a mode or version string).\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: The loaded GeoDataFrame from the matched parquet file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If no file matching the pattern is found.\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(input_folder, f\"{plz}_*_isoDonuts_6x5min__{m}_simp0002.parquet\")\n",
    "    matched_files = glob.glob(pattern)\n",
    "\n",
    "    if matched_files:\n",
    "        return gpd.read_parquet(matched_files[0])\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No matching file found for pattern: {pattern}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "029d7478-6a9d-4ce5-a5b4-e4884b361cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing PLZ 1/1: 88636\n",
      "Processing bike ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10028/10028 [00:06<00:00, 1454.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cargo_bike ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11921/11921 [00:08<00:00, 1445.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing my_bike_cycleways ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9020/9020 [00:06<00:00, 1456.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####__________####\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#plz = \"50126\"\n",
    "\n",
    "## test one plz only:\n",
    "#plz_difference_to_calc=[\"53925\"]\n",
    "\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder_csv, exist_ok=True)\n",
    "\n",
    "modes = [\"bike\", \"cargo_bike\", \"my_bike_cycleways\"]\n",
    "\n",
    "# Total number of PLZs\n",
    "total_plz = len(plz_difference_to_calc)\n",
    "\n",
    "#for plz in valid_plz:\n",
    "#for plz in plz_difference_to_calc:\n",
    "#    print (plz)\n",
    "for idx, plz in enumerate(plz_difference_to_calc, 1):\n",
    "    print(f\"\\nProcessing PLZ {idx}/{total_plz}: {plz}\")\n",
    "    \n",
    "    acc2raster_modes=pd.DataFrame()\n",
    "    pois_w_score_all=pd.DataFrame()\n",
    "    for m in modes:\n",
    "        print (\"Processing\", m, \"...\")\n",
    "        #isodons= gpd.read_parquet(input_folder_isodon+plz+\"_25-03-15_isoDonuts_6x5min__\"+m+\"_simp0002.parquet\")\n",
    "        try:\n",
    "            isodons = read_isodon_file(input_folder_isodon, plz, m)\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "\n",
    "        #isodons=isodons[:30].copy()\n",
    "        acc2raster_mode, pois_w_score=add_access_score(isodons, m)\n",
    "        pois_w_score[\"mode\"]=m\n",
    "        pois_w_score[\"plz\"]=plz\n",
    "        pois_w_score=pois_w_score[[\"plz\",\"id\",\"mode\",\"poi_index\",\"time_bucket\",\"name\",\"cat\",\"score\",\"coeff\",\"poi_type\"]].copy()\n",
    "                \n",
    "        acc2raster_modes=pd.concat([acc2raster_modes, acc2raster_mode])\n",
    "        pois_w_score_all=pd.concat([pois_w_score_all, pois_w_score])\n",
    "    \n",
    "    acc2raster_modes.to_csv(output_folder_csv+plz+\"_acc2raster_.csv\")\n",
    "    pois_w_score_all.to_parquet(output_folder_csv+plz+\"_pois_w_score_all.parquet\")\n",
    "    print (\"####__________####\")\n",
    "    print (\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7253a-f15f-4a38-bfea-87980fb98db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9555fc5-572e-4f2a-85e9-a452036c175a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e22de3-6d38-4919-a894-3d180f0d577f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673911f2-2e0e-4319-bf6b-bd8f8a878167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de973b3-f4ec-4921-a1c6-79e9cff5670f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d973d-b36f-4002-980f-9fe047987caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07335093-c735-4aa0-986b-04805e88eb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a5eda-ae15-45fe-b6c7-d7f093aa8d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc88539-9d79-4f51-ae98-5044a94be961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
